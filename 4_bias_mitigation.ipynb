{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Balancing and Bias Mitigation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do List\n",
    "\n",
    "- [x] Upsampling and downsampling and assess performance by category  \n",
    "- [ ] Debiasing strategies  \n",
    "- [x] Switch model architecture (RF, XGBoost, etc.)  \n",
    "- [ ] Switch feature set (use all features, use subset of features)  \n",
    "- [x] Switch evaluation metric (AUROC, Accuracy, etc.)  \n",
    "- [ ] Bootstrap for confidence intervals \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tableone import TableOne\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading original datasets\n",
    "original_data = pd.read_csv('../preprocessed_data.csv')\n",
    "\n",
    "# Loading altered datasets\n",
    "data_altered_20_percent_african_american= pd.read_csv('../data_altered_20_percent_african_american.csv')\n",
    "data_altered_80_percent_female = pd.read_csv('../data_altered_80_percent_female.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the models for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Original\n",
    "original_rf_loaded = joblib.load(\"../original_data_random_forest_model.pkl\")\n",
    "\n",
    "# Random Forest Altered 20% African American\n",
    "altered_rf_loaded = joblib.load(\"../altered_rf_model.pkl\")\n",
    "\n",
    "# Random Forest Altered 80% Female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model with upsampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split for Upsampling\n",
    "\n",
    "- With stratify=y, both train and test sets will preserve the ratio of the classes from the original data, making the results more representative and the model's performance more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = original_data\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['gender_M', 'ethnicity_Other/Unknown'])\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns=['hospital_death'])\n",
    "y = data['hospital_death']\n",
    "\n",
    "# Split data first (before upsampling)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "AUROC: 0.83\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     14210\n",
      "           1       0.57      0.14      0.22      1305\n",
      "\n",
      "    accuracy                           0.92     15515\n",
      "   macro avg       0.75      0.56      0.59     15515\n",
      "weighted avg       0.90      0.92      0.90     15515\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14075   135]\n",
      " [ 1123   182]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assign class weights automatically (higher weight for underrepresented class)\n",
    "rf_model_balanced = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\")\n",
    "rf_model_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model_balanced.predict(X_test)\n",
    "y_pred_proba = rf_model_balanced.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"AUROC: {auroc:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling the minority class for prediction\n",
    "\n",
    "This function balances an imbalanced dataset by duplicating (upsampling) the minority class so that it has the same number of samples as the majority class.\n",
    "\n",
    "**üîç Example Before & After**\n",
    "\n",
    "| Class         | Original Count | After Upsampling |\n",
    "|--------------|---------------|------------------|\n",
    "| Survived (0) | 10,000        | 10,000          |\n",
    "| Died (1)     | 2,000         | 10,000 (upsampled) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **True Upsampling (Duplicate Minority Class)**\n",
    "def upsample_minority(X, y):\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    \n",
    "    # Separate majority and minority classes\n",
    "    majority = df[df['hospital_death'] == 0]\n",
    "    minority = df[df['hospital_death'] == 1]\n",
    "    \n",
    "    print(majority.shape)\n",
    "    print(minority.shape)\n",
    "    # Upsample the minority class by repeating existing samples\n",
    "    minority_upsampled = minority.sample(n=len(majority), replace=True, random_state=42)\n",
    "\n",
    "    # Combine the upsampled minority class with the majority class\n",
    "    upsampled_df = pd.concat([majority, minority_upsampled])\n",
    "\n",
    "    # Shuffle the dataset to mix samples well\n",
    "    upsampled_df = upsampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return upsampled_df.drop(columns=['hospital_death']), upsampled_df['hospital_death']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the upsampling and train the Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56842, 39)\n",
      "(5218, 39)\n",
      "Accuracy: 0.92\n",
      "AUROC: 0.83\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     14210\n",
      "           1       0.52      0.27      0.36      1305\n",
      "\n",
      "    accuracy                           0.92     15515\n",
      "   macro avg       0.73      0.63      0.66     15515\n",
      "weighted avg       0.90      0.92      0.91     15515\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13882   328]\n",
      " [  948   357]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../upsampled_random_forest_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Apply upsampling\n",
    "X_train_upsampled, y_train_upsampled = upsample_minority(X_train, y_train)\n",
    "\n",
    "# Train a Random Forest model on upsampled data\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_upsampled, y_train_upsampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"AUROC: {auroc:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save model\n",
    "joblib.dump(rf_model, \"../upsampled_random_forest_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampled Model Results Summary\n",
    "\n",
    "**Comparison of Original to upsampled**\n",
    "\n",
    "|  | **Original Model** | **Upsampled Model** | **Changes in the Upsampled Model Compared to Original** |\n",
    "|--------------------|----------------|----------------|----------------|\n",
    "| **True Positives (Correct Deaths)** | 269 | **357** | **+88 (Better at catching deaths)** |\n",
    "| **False Negatives (Missed Deaths)** | 1,032 | **948** | **-84 (Fewer missed high-risk patients)** |\n",
    "| **False Positives (Wrongly Predicted Deaths)** | 187 | **328** | **+141 (More cautious in predicting risk)** |\n",
    "| **True Negatives (Correctly Predicted Survivals)** | 14,027 | **13,882** | **-145 (Slight decrease in correctly classified survivals)** |\n",
    "\n",
    "\n",
    "\n",
    "The upsampled model improves detection of high-risk patients by reducing missed deaths (false negatives) from 1,032 to 948 and correctly identifying 88 more deaths than the original model. However, this comes with a trade-off‚Äîmore false positives, increasing from 187 to 328, meaning the model is now more cautious in predicting risk.\n",
    "\n",
    "Overall, the model prioritizes catching more hospital deaths, which is often preferable in healthcare settings where missing critical cases is riskier than raising extra alerts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try downsampling the majority class instead\n",
    "\n",
    "\n",
    "### Downsampling the Majority Class for Prediction\n",
    "\n",
    "This function balances an imbalanced dataset by reducing (downsampling) the majority class so that it has the same number of samples as the minority class. Instead of adding synthetic or duplicate data, it randomly removes majority-class examples to create a more balanced dataset.\n",
    "\n",
    "üîç Example Before & After\n",
    "\n",
    "| Class         | Original Count | After Downsampling |\n",
    "|--------------|---------------|------------------|\n",
    "| Survived (0) | 10,000        | 2,000  (downsampled) |\n",
    "| Died (1)     | 2,000         | 2,000  |\n",
    "\n",
    "\n",
    "This method helps prevent the model from overfitting to the majority class while ensuring that both classes are treated equally during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **True Downsampling (Reduce Majority Class)**\n",
    "def downsample_majority(X, y):\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    \n",
    "    # Separate majority and minority classes\n",
    "    majority = df[df['hospital_death'] == 0]\n",
    "    minority = df[df['hospital_death'] == 1]\n",
    "    \n",
    "    print(\"Majority class size before downsampling:\", majority.shape)\n",
    "    print(\"Minority class size:\", minority.shape)\n",
    "\n",
    "    # Downsample the majority class to match the minority class\n",
    "    majority_downsampled = majority.sample(n=len(minority), random_state=42)\n",
    "\n",
    "    # Combine the downsampled majority class with the minority class\n",
    "    downsampled_df = pd.concat([majority_downsampled, minority])\n",
    "\n",
    "    # Shuffle the dataset to mix samples well\n",
    "    downsampled_df = downsampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return downsampled_df.drop(columns=['hospital_death']), downsampled_df['hospital_death']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the downsampling and retrain a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class size before downsampling: (56842, 39)\n",
      "Minority class size: (5218, 39)\n",
      "Accuracy: 0.77\n",
      "AUROC: 0.84\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.77      0.86     14210\n",
      "           1       0.23      0.78      0.36      1305\n",
      "\n",
      "    accuracy                           0.77     15515\n",
      "   macro avg       0.60      0.77      0.61     15515\n",
      "weighted avg       0.91      0.77      0.82     15515\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10893  3317]\n",
      " [  287  1018]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../downsampled_random_forest_model.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = original_data\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['gender_M', 'ethnicity_Other/Unknown'])\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns=['hospital_death'])\n",
    "y = data['hospital_death']\n",
    "\n",
    "# Split data first (before upsampling)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# Apply downsampling\n",
    "X_train_downsampled, y_train_downsampled = downsample_majority(X_train, y_train)\n",
    "\n",
    "# Train a Random Forest model on upsampled data\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_downsampled, y_train_downsampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"AUROC: {auroc:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save model\n",
    "joblib.dump(rf_model, \"../downsampled_random_forest_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampled Model Results Summary\n",
    "After downsampling, the model learns more evenly from both classes, leading to higher recall for the minority class (78%) but lower precision (23%).\n",
    "\n",
    "- Accuracy (77%) is lower than the original model, but this is expected since we now prioritize balancing class predictions.\n",
    "- AUROC (0.84) shows the model is still good at distinguishing between classes.\n",
    "- Recall for hospital deaths (78%) improved significantly, meaning the model is much better at catching high-risk patients.\n",
    "- Precision for hospital deaths (23%) is low, indicating more false positives.\n",
    "- False negatives dropped from 1,032 (original model) to 287, meaning fewer missed critical cases.\n",
    "\n",
    "The trade-off: fewer missed deaths (higher recall) but more false alarms (lower precision). This approach ensures more cautious risk prediction, which is often preferable in healthcare applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the bias per category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which categories to analyze\n",
    "original_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexible Bias Assessment Function\n",
    "This code checks if the AI model is fair by seeing how well it predicts hospital outcomes for different groups, like gender and ethnicity. It looks at accuracy (how often the model is right) and AUROC (how well it separates high-risk from low-risk patients).\n",
    "\n",
    "If the model performs worse for certain groups, it might be biased, meaning it doesn't work equally well for everyone. This helps us identify unfairness and improve the model to make healthcare predictions more fair and reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **Flexible Bias Assessment Function**\n",
    "def assess_bias(model, X_test, y_test, feature_name):\n",
    "    \"\"\"Evaluate model performance for different demographic groups.\"\"\"\n",
    "    \n",
    "    # Ensure the feature exists in the dataset\n",
    "    if feature_name not in X_test.columns:\n",
    "        print(f\"Skipping {feature_name}: Not found in dataset\")\n",
    "        return pd.DataFrame(columns=[\"Category\", \"Accuracy\", \"AUROC\"])\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Check if model supports `predict_proba` (some models like SVM do not)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_pred_proba = y_pred  # Use predictions directly if no probabilities are available\n",
    "    \n",
    "    # Analyze performance across each category\n",
    "    categories = X_test[feature_name].unique()\n",
    "    results = []\n",
    "\n",
    "    for category in categories:\n",
    "        mask = X_test[feature_name] == category  # Boolean mask\n",
    "        y_true_group = y_test[mask]\n",
    "        y_pred_group = y_pred[mask]\n",
    "        y_proba_group = y_pred_proba[mask]\n",
    "\n",
    "        if len(y_true_group) == 0:\n",
    "            continue  # Skip if no data for this category\n",
    "\n",
    "        accuracy_group = accuracy_score(y_true_group, y_pred_group)\n",
    "        auroc_group = roc_auc_score(y_true_group, y_proba_group) if len(set(y_true_group)) > 1 else np.nan  # Avoid AUROC error for single class\n",
    "\n",
    "        results.append([category, accuracy_group, auroc_group])\n",
    "\n",
    "    return pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"AUROC\"])\n",
    "\n",
    "\n",
    "# **Example: Running Bias Analysis for Any Model**\n",
    "\n",
    "    # Choose which features to evaluate\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    features_to_check = [\"gender_F\", \"ethnicity_Caucasian\", \"ethnicity_African American\", \"ethnicity_Hispanic\", \"ethnicity_Native American\"]\n",
    "\n",
    "    for feature in features_to_check:\n",
    "        print(f\"\\nBias Analysis for {feature}:\")\n",
    "        bias_results = assess_bias(model, X_test, y_test, feature)\n",
    "        print(bias_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Evaluating Random Forest:\n",
      "\n",
      "Bias Analysis for gender_F:\n",
      "   Category  Accuracy     AUROC\n",
      "0      True  0.915752  0.828310\n",
      "1     False  0.919453  0.840209\n",
      "\n",
      "Bias Analysis for ethnicity_Caucasian:\n",
      "   Category  Accuracy     AUROC\n",
      "0     False  0.922971  0.848373\n",
      "1      True  0.916169  0.831086\n",
      "\n",
      "Bias Analysis for ethnicity_African American:\n",
      "   Category  Accuracy     AUROC\n",
      "0     False  0.915774  0.834787\n",
      "1      True  0.933923  0.834359\n",
      "\n",
      "Bias Analysis for ethnicity_Hispanic:\n",
      "   Category  Accuracy     AUROC\n",
      "0     False  0.918746  0.835715\n",
      "1      True  0.895062  0.815713\n",
      "\n",
      "Bias Analysis for ethnicity_Native American:\n",
      "   Category  Accuracy     AUROC\n",
      "0     False  0.917978  0.833912\n",
      "1      True  0.893617  0.910000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "\n",
    "model = joblib.load('../upsampled_random_forest_model.pkl')\n",
    "\n",
    "print(\"\\nüîç Evaluating Random Forest:\")\n",
    "evaluate_model(rf_model, X_test, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLClass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
