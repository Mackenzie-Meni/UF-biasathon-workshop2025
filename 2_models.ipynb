{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Women in Data Science Dataset\n",
    "\n",
    "**Dataset:** Women in Data Science (91,713 encounters)  \n",
    "**Microskill:** Model Comparison  \n",
    "**Date:** February 13, 2025  \n",
    "**Authors:** Jeremy Balch & Mackenzie Meni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do List\n",
    "\n",
    "- [ ] Upsampling and downsampling and assess performance by category  \n",
    "- [ ] Debiasing strategies  \n",
    "- [ ] Switch model architecture (RF, XGBoost, etc.)  \n",
    "- [ ] Switch feature set (use all features, use subset of features)  \n",
    "- [ ] Switch evaluation metric (AUROC, Accuracy, etc.)  \n",
    "- [ ] Bootstrap for confidence intervals \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tableone import TableOne\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our preprocessed data from notebook '1_data_handling.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the train test split for the Random Forrest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (62060, 38)\n",
      "X_test shape: (15515, 38)\n",
      "y_train shape: (62060,)\n",
      "y_test shape: (15515,)\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'gender_M' and 'ethnicity_Other' columns\n",
    "data = data.drop(columns=['gender_M', 'ethnicity_Other/Unknown'])\n",
    "\n",
    "# Define your features and target variable\n",
    "X = data.drop('hospital_death', axis=1)  # Features\n",
    "y = data['hospital_death']               # Target variable\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Shapes should be:\n",
    "# X_train shape: (62060, 38)\n",
    "# X_test shape: (15515, 38)\n",
    "# y_train shape: (62060,)\n",
    "# y_test shape: (15515,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "AUROC: 0.84\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     14214\n",
      "           1       0.59      0.21      0.31      1301\n",
      "\n",
      "    accuracy                           0.92     15515\n",
      "   macro avg       0.76      0.60      0.63     15515\n",
      "weighted avg       0.90      0.92      0.90     15515\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14027   187]\n",
      " [ 1032   269]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(rf_model, \"../original_data_random_forest_model.pkl\")\n",
    "\n",
    "\n",
    "# Calculate AUROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUROC: {auroc:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a MLP Model:\n",
    "\n",
    "Whatâ€™s Inside the Model?\n",
    "- Three Key Processing Steps:\n",
    "\n",
    "    - The first layer extracts important patterns from patient data.\n",
    "    - The second layer refines the information further.\n",
    "    - The final layer makes the prediction: high risk or low risk.\n",
    "\n",
    "- Learning with Feedback:\n",
    "    - The model improves over time by comparing its predictions to actual outcomes and adjusting accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 9.9698\n",
      "Epoch 2/20, Loss: 3.1315\n",
      "Epoch 3/20, Loss: 1.0413\n",
      "Epoch 4/20, Loss: 0.4193\n",
      "Epoch 5/20, Loss: 0.3042\n",
      "Epoch 6/20, Loss: 0.2995\n",
      "Epoch 7/20, Loss: 0.2888\n",
      "Epoch 8/20, Loss: 0.2889\n",
      "Epoch 9/20, Loss: 0.2889\n",
      "Epoch 10/20, Loss: 0.2888\n",
      "Epoch 11/20, Loss: 0.2887\n",
      "Epoch 12/20, Loss: 0.2887\n",
      "Epoch 13/20, Loss: 0.2887\n",
      "Epoch 14/20, Loss: 0.2887\n",
      "Epoch 15/20, Loss: 0.2888\n",
      "Epoch 16/20, Loss: 0.2887\n",
      "Epoch 17/20, Loss: 0.2887\n",
      "Epoch 18/20, Loss: 0.2889\n",
      "Epoch 19/20, Loss: 0.2887\n",
      "Epoch 20/20, Loss: 0.2887\n",
      "Accuracy: 0.92\n",
      "AUROC: 0.50\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     14214\n",
      "           1       0.00      0.00      0.00      1301\n",
      "\n",
      "    accuracy                           0.92     15515\n",
      "   macro avg       0.46      0.50      0.48     15515\n",
      "weighted avg       0.84      0.92      0.88     15515\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14214     0]\n",
      " [ 1301     0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns=['hospital_death'])  # Features\n",
    "y = data['hospital_death']  # Target variable\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train.astype(np.float32).values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.astype(np.float32).values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Create TensorDataset and DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_classes=2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)  # Keep raw logits\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "input_size = X_train.shape[1]\n",
    "num_classes = len(set(y_train))\n",
    "model = MLP(input_size, hidden_size=64, num_classes=num_classes)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train model\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluate model\n",
    "model.eval()\n",
    "y_pred_list = []\n",
    "y_pred_proba_list = []\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = model(batch_X)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predictions = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "        y_pred_list.extend(predictions.cpu().numpy())\n",
    "        y_pred_proba_list.extend(probabilities[:, 1].cpu().numpy())\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_list)\n",
    "auroc = roc_auc_score(y_test, y_pred_proba_list)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"AUROC: {auroc:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_list))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Does the MLP Have an AUROC of 0.5 Despite High Accuracy?\n",
    "\n",
    "- **AUROC (Area Under the Receiver Operating Characteristic Curve)** measures how well the model separates positive and negative cases. A value of 0.5 means the model is no better than  random guessing for the minority class.\n",
    "\n",
    "- **Accuracy** is misleading in imbalanced datasets because a model can achieve high accuracy simply by predicting the majority class most of the time.\n",
    "\n",
    "#### Since the **dataset has very few instances of the minority class** (e.g., hospital deaths), the MLP (neural network) likely learned to predict the majority class nearly all the time. This results in:\n",
    "\n",
    " - High accuracy (because it's correct most of the time on the dominant class). \n",
    " - Low AUROC (because it's not distinguishing between classes well).\n",
    "\n",
    "### Why Does the Random Forest (RF) Perform Better?\n",
    "-  Tree-based models like Random Forest are more robust to **imbalanced data** because they can focus on the minority class better, using techniques like bootstrap aggregation and feature splits that naturally find small but important patterns in the data.\n",
    "\n",
    "-   RF has an AUROC of 0.84, meaning it is significantly better at distinguishing between classes, likely because it is making more meaningful predictions for the minority class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain your Random Forest model with your altered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading altered datasets\n",
    "data_altered_20_percent_african_american= pd.read_csv('../data_altered_20_percent_african_american.csv')\n",
    "data_altered_80_percent_female = pd.read_csv('../data_altered_80_percent_female.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (62060, 38)\n",
      "X_test shape: (15515, 38)\n",
      "y_train shape: (62060,)\n",
      "y_test shape: (15515,)\n"
     ]
    }
   ],
   "source": [
    "# choose the data set to experiment with\n",
    "data_altered = data_altered_20_percent_african_american\n",
    "\n",
    "# Drop the 'gender_M' and 'ethnicity_Other' columns\n",
    "data_altered = data_altered.drop(columns=['gender_M', 'ethnicity_Other/Unknown'])\n",
    "\n",
    "\n",
    "# Define your features and target variable\n",
    "X = data_altered.drop('hospital_death', axis=1)  # Features\n",
    "y = data_altered['hospital_death']               # Target variable\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train_altered, X_test_altered, y_train_altered, y_test_altered = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(\"X_train shape:\", X_train_altered.shape)\n",
    "print(\"X_test shape:\", X_test_altered.shape)\n",
    "print(\"y_train shape:\", y_train_altered.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "### Retrain Model on Altered Data\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model_altered = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model_altered.fit(X_train_altered, y_train_altered)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(rf_model_altered, f'../altered_rf_model.pkl')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_altered = rf_model_altered.predict(X_test_altered)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLClass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
