{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Bias-Athon 2025!\n",
    "\n",
    "This notebook introduces the learning objectives, prepares the datasets, and provides an overview of the workshop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives:\n",
    "1. Explore how **data biases** (e.g., measurement errors or missingness) impact downstream tasks. \n",
    "2. Understand and simulate **concept drift**: altering the relationship between features and the target variable.\n",
    "3. Simulate **prior probability drift**: changing the incidence rate of the target variable.\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Create and save datasets with introduced biases (e.g., SpO2 and lactate modifications).\n",
    "- Generate drifted datasets to simulate real-world challenges in data analysis.\n",
    "- Split the data into train and test sets for further analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule (2 Hours)\n",
    "\n",
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Materials\n",
    "\n",
    " - **WiDS dataset** - Download the dataset (\"training_v2.csv\") [here](https://www.kaggle.com/competitions/widsdatathon2020/data).\n",
    "\n",
    " - **Data Dictionary** - Refer to the provided documentation for variable definitions.\n",
    "\n",
    " - **Bias-Athon GitHub Repository** - Clone the repository for all notebooks and datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"data/training_v2.csv\")\n",
    "with pd.option_context('display.max_rows', 5, 'display.max_columns', None):\n",
    "    display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: SpO2 Modifications (Bias 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline data distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['d1_spo2_min'].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['d1_spo2_min'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['d1_spo2_max'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Bias to Black Patient's SpO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase SpO2 of Black patients by 10%\n",
    "print(\"Adding bias to SpO2 for Black patients...\")\n",
    "delta_to_add = 10\n",
    "\n",
    "data['d1_spo2_min_new'] = data.apply(\n",
    "    lambda row: \n",
    "    row.d1_spo2_min + delta_to_add if \n",
    "        ((row.d1_spo2_min + delta_to_add) <= 100) & (row.ethnicity == 'African American')\n",
    "    else (100 if \n",
    "        ((row.d1_spo2_min + delta_to_add) > 100) & (row.ethnicity == 'African American')\n",
    "    else (row.d1_spo2_min)),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the SpO2 Modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distributions before and after bias\n",
    "print(\"Before modification:\")\n",
    "print(data.loc[data.ethnicity == 'African American','d1_spo2_min'].describe())\n",
    "print(\"After modification:\")\n",
    "print(data.loc[data.ethnicity == 'African American','d1_spo2_min_new'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. # Lactate Modifications (Bias 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop all lactate values for Black patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Dropping lactate values for Black patients...\")\n",
    "data['d1_lactate_max_new'] = data.apply(\n",
    "    lambda row: \n",
    "    np.nan if row.ethnicity == 'African American'\n",
    "    else row.d1_lactate_max,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check new missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"New missingness for lactate:\")\n",
    "print(data.loc[data.ethnicity == 'African American', 'd1_lactate_max_new'].isna().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Introduce Concept Drift in Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Drift\n",
    "**Goal:** Alter the relationship between SpO2 and hospital_death for all patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Introducing Concept Drift...\")\n",
    "data['hospital_death_concept_drift'] = data.apply(\n",
    "    lambda row: 1 if row['d1_spo2_min'] < 92 else row['hospital_death'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Prior Probability Drift\n",
    "**Goal:** Change the distribution of hospital_death for African American patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Introducing Prior Probability Drift...\")\n",
    "data['hospital_death_prior_drift'] = data.apply(\n",
    "    lambda row: 0 if row['hospital_death'] == 1 and row['ethnicity'] == 'African American' and np.random.rand() < 0.5 else row['hospital_death'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display basic statistics for the new target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Original Hospital Death Rate:\", data['hospital_death'].mean())\n",
    "print(\"Concept Drift Hospital Death Rate:\", data['hospital_death_concept_drift'].mean())\n",
    "print(\"Prior Probability Drift Hospital Death Rate:\", data['hospital_death_prior_drift'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Limit Columns for Analysis\n",
    "\n",
    "**Goal:** Focus on a curated set of features for analysis to reduce redundancy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Limiting Columns...\")\n",
    "data = data[[\n",
    "    'encounter_id', 'patient_id', 'hospital_id', # IDs\n",
    "    'age', 'ethnicity', 'gender', 'bmi',        # Patient demographics\n",
    "    'icu_admit_source', 'icu_type',            # ICU stay info\n",
    "    'd1_heartrate_max', 'd1_heartrate_min',    # Vital signs\n",
    "    'd1_mbp_max', 'd1_mbp_min',\n",
    "    'd1_sysbp_max', 'd1_sysbp_min',\n",
    "    'd1_diasbp_max', 'd1_diasbp_min',\n",
    "    'd1_resprate_max', 'd1_resprate_min',\n",
    "    'd1_temp_max', 'd1_temp_min',\n",
    "    'd1_albumin_min', 'd1_bilirubin_max',      # Labs\n",
    "    'd1_bun_max', 'd1_calcium_max', 'd1_calcium_min',\n",
    "    'd1_creatinine_max', 'd1_glucose_max', 'd1_glucose_min',\n",
    "    'd1_hco3_min', 'd1_hemaglobin_min', 'd1_hematocrit_min',\n",
    "    'd1_inr_max', 'd1_platelets_min',\n",
    "    'd1_potassium_max', 'd1_potassium_min',\n",
    "    'd1_sodium_max', 'd1_sodium_min',\n",
    "    'd1_wbc_max',\n",
    "    # Original and modified target variables\n",
    "    'hospital_death',\n",
    "    'hospital_death_concept_drift',\n",
    "    'hospital_death_prior_drift',\n",
    "    'd1_spo2_min_new',\n",
    "    'd1_lactate_max_new',\n",
    "    'd1_spo2_min',\n",
    "    'd1_lactate_max'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Train-Test Split\n",
    "**Goal:** Split the dataset into 80% training and 20% testing subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "print(\"Train shape:\", data_train.shape)\n",
    "print(\"Test shape:\", data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check balancing of the mortality outcome in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Mortality Rate in Train:\", data_train['hospital_death'].mean())\n",
    "print(\"Concept Drift Mortality Rate in Train:\", data_train['hospital_death_concept_drift'].mean())\n",
    "print(\"Prior Drift Mortality Rate in Train:\", data_train['hospital_death_prior_drift'].mean())\n",
    "\n",
    "print(\"Original Mortality Rate in Test:\", data_test['hospital_death'].mean())\n",
    "print(\"Concept Drift Mortality Rate in Test:\", data_test['hospital_death_concept_drift'].mean())\n",
    "print(\"Prior Drift Mortality Rate in Test:\", data_test['hospital_death_prior_drift'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Save the DataFrames as CSV Files\n",
    "**Goal:** Ensure all datasets are saved for subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a subfolder called 'data_split' if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists('data_split'):\n",
    "    os.makedirs('data_split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Saving datasets...\")\n",
    "data_train.to_csv('data_split/wids_train.csv', index=False)\n",
    "data_test.to_csv('data_split/wids_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save drifted datasets separately for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train[['hospital_death_concept_drift']].to_csv('data_split/wids_train_concept_drift.csv', index=False)\n",
    "data_train[['hospital_death_prior_drift']].to_csv('data_split/wids_train_prior_drift.csv', index=False)\n",
    "data_test[['hospital_death_concept_drift']].to_csv('data_split/wids_test_concept_drift.csv', index=False)\n",
    "data_test[['hospital_death_prior_drift']].to_csv('data_split/wids_test_prior_drift.csv', index=False)\n",
    "\n",
    "print(\"Dataset preparation complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
